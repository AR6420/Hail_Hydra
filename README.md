<p align="center">
  <img src="https://img.shields.io/badge/ğŸ‰-HAIL_HYDRA-darkred?style=for-the-badge&labelColor=black" alt="Hail Hydra" />
</p>

<h1 align="center">ğŸ‰ H Y D R A</h1>

<p align="center">
  <strong>Multi-Headed Speculative Execution for Claude Code</strong>
</p>

<p align="center">
  <em>"Cut off one head, two more shall take its place."</em><br/>
  <em>Except here â€” every head is doing your work faster and cheaper.</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Opus_4.6-ğŸ§ _The_Body-7C3AED?style=flat-square" alt="Opus" />
  <img src="https://img.shields.io/badge/Sonnet_4.6-ğŸ”µ_Smart_Heads-3B82F6?style=flat-square" alt="Sonnet" />
  <img src="https://img.shields.io/badge/Haiku_4.5-ğŸŸ¢_Fast_Heads-22C55E?style=flat-square" alt="Haiku" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Speed-2--3Ã—_Faster-22C55E?style=flat-square&logo=zap&logoColor=white" alt="Speed" />
  <img src="https://img.shields.io/badge/Cost-~50%25_Cheaper-3B82F6?style=flat-square&logo=piggy-bank&logoColor=white" alt="Cost" />
  <img src="https://img.shields.io/badge/Quality-Zero_Loss-7C3AED?style=flat-square&logo=shield-check&logoColor=white" alt="Quality" />
  <img src="https://img.shields.io/badge/Mode-Always_On-darkred?style=flat-square&logo=power&logoColor=white" alt="Always On" />
</p>

---

## ğŸ§¬ What is Hydra?

You know how in the movies, Hydra had agents embedded *everywhere*, silently getting things done in the background? That's exactly what this framework does for your Claude Code sessions.

**Hydra** is a task-level speculative execution framework inspired by [Speculative Decoding](https://arxiv.org/abs/2302.01318) in LLM inference. Instead of making one expensive model (Opus 4.6) do *everything* â€” from searching files to writing entire modules â€” Hydra deploys a team of specialized **"heads"** running on faster, cheaper models that handle the grunt work.

The result? **Opus becomes a manager, not a laborer.** It classifies tasks, dispatches them to the right head, glances at the output, and moves on. The user never notices. It's invisible. It's always on.

> **Four built-in speed optimizations** reduce overhead at every stage: speculative pre-dispatch
> (scout launches in parallel with task classification), session indexing (codebase context
> persists across turns â€” no re-exploration), fire-and-forget dispatch (non-critical agents run
> in the background without blocking downstream work), and confidence-based auto-accept (raw
> factual outputs skip Opus review entirely).

> **Think of it this way:**
>
> Would you hire a $500/hr architect to carry bricks? No. You'd have them design the building and let the crew handle construction. That's Hydra.

---

## âœ¨ Features

- **Seven specialized heads** â€” Haiku 4.5 (fast) and Sonnet 4.6 (capable) heads for every task type
- **Auto-Guard** â€” hydra-guard (Haiku 4.5) automatically scans code changes for security issues after every hydra-coder run
- **Configurable modes** â€” `conservative`, `balanced` (default), or `aggressive` delegation via `hydra.config.md`
- **Quick commands** â€” `hydra status`, `hydra quiet`, `hydra verbose`, `hydra config` for session control
- **Custom agent templates** â€” Add your own heads using `templates/custom-agent.md`
- **Session indexing** â€” Codebase context persists across turns; no re-exploration on every prompt
- **Speculative pre-dispatch** â€” hydra-scout launches in parallel with task classification, saving 2â€“3 seconds per task
- **Dispatch log** â€” Transparent audit trail showing which agents ran, what model, and outcome

---

## ğŸ¤” Why I Built This

After Opus 4.6 dropped, I noticed something frustrating â€” code execution felt slowww. Reallyyy Slow. Not because the model was worse, but because I was feeding everything through one massive model. Every file read, every grep, every test run, every docstring â€” all burning through Opus-tier tokens. The result? Frequent context compaction, more hallucinations, and an API bill that made me wince.

So I started experimenting. I switched to Haiku for the simple stuff â€” running commands, tool calls, file exploration. Sonnet for code generation, refactoring, reviews. And kept Opus only for what it's actually good at: planning, architecture, and the hard decisions. The result surprised me. Same code quality. Sometimes better â€” because each model was operating within a focused context window instead of one overloaded one.

Five agents. Five separate context windows. Each with a clearly defined job. They do the work, and only pass results back to the brain â€” Opus. The outcome:

- Longer coding sessions (less compaction, less context blowup)
- Drastically reduced API costs (Haiku 4.5 is 5Ã— cheaper than Opus 4.6)
- Faster execution (Haiku 4.5 responds ~10Ã— faster)
- Same or better code quality (focused context > bloated context)
- Zero manual model switching (this is the big one)

Because that was the real pain â€” manually switching between models for every task tier to save costs. Every. Single. Time. So I built a framework that does it for me. And honestly? It does it better than I did. That was hard to admit, but here we are.

I also didn't want it to be boring. So I gave it teeth, heads, and a battle cry. If you prefer something more buttoned-up, the [`spec-exec`](../../tree/spec-exec) branch has the same framework with zero theatrics.

*Hail Hydra. Have fun.*

---

## ğŸ’¡ The Theory (for nerds)

Speculative decoding (Chen et al., 2023) accelerates LLM inference by having a small **draft model** propose tokens that a large **target model** verifies in parallel. Since verifying K tokens costs roughly the same as generating 1 token, you get 2â€“2.5Ã— speedup with **zero quality loss**.

Hydra applies this at the **task level**:

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  SPECULATIVE DECODING (tokens)  â”‚
                          â”‚                                 â”‚
                          â”‚  Small model drafts K tokens    â”‚
                          â”‚  Big model verifies in parallel â”‚
                          â”‚  Accept or reject + resample    â”‚
                          â”‚  Result: 2-2.5Ã— speedup         â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                   Same idea,
                                  bigger scale
                                        â”‚
                                        â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  ğŸ‰ HYDRA (tasks)               â”‚
                          â”‚                                 â”‚
                          â”‚  Haiku/Sonnet drafts the task   â”‚
                          â”‚  Opus verifies (quick glance)   â”‚
                          â”‚  Accept or redo yourself        â”‚
                          â”‚  Result: 2-3Ã— speedup           â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The math is simple: if 70% of tasks can be handled by Haiku 4.5 (10Ã— faster, 5Ã— cheaper) and 20% by Sonnet 4.6 (3Ã— faster, ~1.7Ã— cheaper), your effective speed and cost improve dramatically â€” even accounting for the occasional rejection.

---

## ğŸ—ï¸ Architecture

```
User Request
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                      â”‚
    â–¼                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ§  ORCHESTRATOR (Opus)     â”‚            â”‚  ğŸŸ¢ hydra-scout (Haiku 4.5)  â”‚
â”‚  Classifies task            â”‚            â”‚  IMMEDIATE pre-dispatch:      â”‚
â”‚  Plans waves                â”‚            â”‚  "Find files relevant to      â”‚
â”‚  Decides blocking / not     â”‚            â”‚   [user's request]"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚         (unless Session Index already covers)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ (scout + classification both ready)
                      [Session Index updated]
                                â”‚
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Wave N  (parallel dispatch, index context injected)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  BLOCKING         â”‚  NON-BLOCKING (fire & forget)    â”‚
    â–¼                   â–¼                                  â”‚
 [coder]            [scribe] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
 Results arrive
    â”‚
    â”œâ”€â”€ Raw data / clean pass? â†’ AUTO-ACCEPT â†’ (updates Session Index if scout)
    â””â”€â”€ Code / analysis / user-facing docs? â†’ Orchestrator verifies
         â”‚
         â–¼
   User gets result  +  non-blocking outputs appended when ready
```

---

## ğŸ² The Seven Heads

| Head | Model | Speed | Role | Personality |
|:-----|:------|:------|:-----|:------------|
| **hydra-scout (Haiku 4.5)** | ğŸŸ¢ Haiku 4.5 | âš¡âš¡âš¡ | Codebase exploration, file search, reading | *"I've already found it."* |
| **hydra-runner (Haiku 4.5)** | ğŸŸ¢ Haiku 4.5 | âš¡âš¡âš¡ | Test execution, builds, linting, validation | *"47 passed, 3 failed. Here's why."* |
| **hydra-scribe (Haiku 4.5)** | ğŸŸ¢ Haiku 4.5 | âš¡âš¡âš¡ | Documentation, READMEs, comments | *"Documented before you finished asking."* |
| **hydra-guard (Haiku 4.5)** | ğŸŸ¢ Haiku 4.5 | âš¡âš¡âš¡ | Security/quality gate after code changes | *"No secrets. No injection. You're clean."* |
| **hydra-git (Haiku 4.5)** | ğŸŸ¢ Haiku 4.5 | âš¡âš¡âš¡ | Git: commit, branch, diff, stash, log | *"Committed. Conventional message. Clean diff."* |
| **hydra-coder (Sonnet 4.6)** | ğŸ”µ Sonnet 4.6 | âš¡âš¡ | Code implementation, refactoring, features | *"Feature's done. Tests pass."* |
| **hydra-analyst (Sonnet 4.6)** | ğŸ”µ Sonnet 4.6 | âš¡âš¡ | Code review, debugging, analysis | *"Found 2 critical bugs and an N+1 query."* |

### Task Routing Cheat Sheet

```
Is it read-only? â”€â”€â”€ Yes â”€â”€â†’ Finding files?
    â”‚                           â”œâ”€â”€ Yes: hydra-scout (Haiku 4.5) ğŸŸ¢
    â”‚                           â””â”€â”€ No:  hydra-analyst (Sonnet 4.6) ğŸ”µ
    â”‚
    No â”€â”€â†’ Is it a git operation? â”€â”€â”€ Yes â”€â”€â†’ hydra-git (Haiku 4.5) ğŸŸ¢
    â”‚
    No â”€â”€â†’ Is it a security scan? â”€â”€â”€ Yes â”€â”€â†’ hydra-guard (Haiku 4.5) ğŸŸ¢
    â”‚
    No â”€â”€â†’ Just running a command? â”€â”€â”€ Yes â”€â”€â†’ hydra-runner (Haiku 4.5) ğŸŸ¢
    â”‚
    No â”€â”€â†’ Writing docs only? â”€â”€â”€ Yes â”€â”€â†’ hydra-scribe (Haiku 4.5) ğŸŸ¢
    â”‚
    No â”€â”€â†’ Clear implementation approach? â”€â”€â”€ Yes â”€â”€â†’ hydra-coder (Sonnet 4.6) ğŸ”µ
    â”‚
    No â”€â”€â†’ Needs deep reasoning? â”€â”€â”€ Yes â”€â”€â†’ ğŸ§  Opus 4.6 (handle it yourself)
```

---

## ğŸš€ Installation

### Quick Start (30 seconds)

```bash
# Clone the repo
git clone https://github.com/AR6420/Hail_Hydra.git
cd hydra

# Deploy heads globally (recommended â€” always on, every project)
./scripts/install.sh --user

# ğŸ‰ Hail Hydra! Heads are now active in all Claude Code sessions.
```

### Installation Options

```bash
# User-level â€” available in ALL your Claude Code projects
./scripts/install.sh --user

# Project-level â€” just this one project
./scripts/install.sh --project

# Both â€” maximum coverage
./scripts/install.sh --both

# Check what's deployed
./scripts/install.sh --status

# Remove everything
./scripts/install.sh --uninstall
```

### What Gets Installed Where

```
~/.claude/agents/          â† User-level (all projects)
  â”œâ”€â”€ hydra-scout.md       ğŸŸ¢ hydra-scout (Haiku 4.5)
  â”œâ”€â”€ hydra-runner.md      ğŸŸ¢ hydra-runner (Haiku 4.5)
  â”œâ”€â”€ hydra-scribe.md      ğŸŸ¢ hydra-scribe (Haiku 4.5)
  â”œâ”€â”€ hydra-guard.md       ğŸŸ¢ hydra-guard (Haiku 4.5)
  â”œâ”€â”€ hydra-git.md         ğŸŸ¢ hydra-git (Haiku 4.5)
  â”œâ”€â”€ hydra-coder.md       ğŸ”µ hydra-coder (Sonnet 4.6)
  â””â”€â”€ hydra-analyst.md     ğŸ”µ hydra-analyst (Sonnet 4.6)

.claude/agents/            â† Project-level (one project)
  â””â”€â”€ (same files)
```

> **Note:** Project-level agents take precedence over user-level when both exist. This lets you customize heads per-project if needed.

---

## âš™ï¸ Configuration

Customize Hydra's behavior with an optional config file:

```bash
# Create a default config (user-level â€” applies to all projects)
./scripts/install.sh --config
```

Then edit `~/.claude/hydra/hydra.config.md`:

```markdown
mode: balanced          # conservative | balanced (default) | aggressive
dispatch_log: on        # on (default) | off | verbose
auto_guard: on          # on (default) | off
```

**Project-level config** (overrides user-level):
Place at `.claude/hydra/hydra.config.md` in your project root.

See [`config/hydra.config.md`](config/hydra.config.md) for the full reference with all options.

---

## ğŸ§© Extending Hydra

Add your own specialized head in three steps:

**1. Copy the template:**
```bash
cp templates/custom-agent.md agents/hydra-myspecialist.md
```

**2. Customize the agent** â€” edit the name, description, tools, and instructions.

**3. Deploy it:**
```bash
./scripts/install.sh --user   # or --project
```

Your new head is now discoverable by Claude Code alongside the built-in seven.
See [`templates/custom-agent.md`](templates/custom-agent.md) for the full template with
instructions on writing effective agent descriptions, output formats, and collaboration protocols.

---

## ğŸ“‚ Repository Structure

```
hydra/
â”œâ”€â”€ ğŸ“„ SKILL.md                          # Core framework instructions
â”œâ”€â”€ ğŸ² agents/
â”‚   â”œâ”€â”€ hydra-scout.md                   # ğŸŸ¢ Codebase explorer
â”‚   â”œâ”€â”€ hydra-runner.md                  # ğŸŸ¢ Test & build executor
â”‚   â”œâ”€â”€ hydra-scribe.md                  # ğŸŸ¢ Documentation writer
â”‚   â”œâ”€â”€ hydra-guard.md                   # ğŸŸ¢ Security/quality gate
â”‚   â”œâ”€â”€ hydra-git.md                     # ğŸŸ¢ Git operations
â”‚   â”œâ”€â”€ hydra-coder.md                   # ğŸ”µ Code implementer
â”‚   â””â”€â”€ hydra-analyst.md                 # ğŸ”µ Code reviewer & debugger
â”œâ”€â”€ ğŸ“š references/
â”‚   â”œâ”€â”€ routing-guide.md                 # 30+ task classification examples
â”‚   â””â”€â”€ model-capabilities.md            # What each model excels at
â”œâ”€â”€ âš™ï¸ config/
â”‚   â””â”€â”€ hydra.config.md                  # User configuration template
â”œâ”€â”€ ğŸ“‹ templates/
â”‚   â””â”€â”€ custom-agent.md                  # Template for adding your own heads
â””â”€â”€ ğŸ”§ scripts/
    â””â”€â”€ install.sh                       # One-command deployment
```

---

## ğŸ“Š Expected Impact

| Metric | Without Hydra | With Hydra | Improvement |
|:-------|:-------------|:-----------|:------------|
| **Task Speed** | 1Ã— (Opus for everything) | 2â€“3Ã— faster | ğŸŸ¢ Haiku 4.5 heads respond ~10Ã— faster |
| **API Cost** | 1Ã— (Opus 4.6 for everything) | ~0.5Ã— | ~50% cheaper |
| **Quality** | Opus-level | Opus-level | Zero degradation |
| **User Experience** | Normal | Normal | Invisible â€” zero friction |
| **Overhead per turn (Turn 2+)** | Full re-exploration each turn | Session index reused | ğŸŸ¢ 2-4s saved per turn |
| **Scout/runner verification** | Opus reviews every output | Auto-accepted for factual data | ğŸŸ¢ ~50-60% of outputs skip review |

### How the Savings Work

| Task Type | % of Work | Model Used | Input Cost vs Opus 4.6 | Output Cost vs Opus 4.6 |
|:----------|:----------|:-----------|:----------------------|:-----------------------|
| Exploration, search, tests, docs | ~50% | ğŸŸ¢ Haiku 4.5 | 20% ($1 vs $5/MTok) | 20% ($5 vs $25/MTok) |
| Implementation, review, debugging | ~30% | ğŸ”µ Sonnet 4.6 | 60% ($3 vs $5/MTok) | 60% ($15 vs $25/MTok) |
| Architecture, hard problems | ~20% | ğŸ§  Opus 4.6 | 100% (no change) | 100% (no change) |
| **Blended effective cost** | | | **~48% of all-Opus** | **~48% of all-Opus** |

Note: Blended input = (0.5Ã—$1 + 0.3Ã—$3 + 0.2Ã—$5) / $5 = $2.40/$5 â‰ˆ 48%.
Rounded to **~50% blended cost reduction** overall.
Savings calculated against Opus 4.6 ($5/$25 per MTok) as of February 2026.

### Measure Your Savings

The most accurate way to measure Hydra's impact â€” no estimation, real numbers:

1. Start a Claude Code session **without** Hydra installed
2. Complete a representative coding task
3. Note the session cost from Claude Code's cost display
4. Start a **new** session **with** Hydra installed
5. Complete a similar task
6. Compare the two costs

That's it. Real data beats theoretical calculations every time.

#### What to expect (based on February 2026 API pricing)
With a typical task distribution (50% Haiku 4.5, 30% Sonnet 4.6, 20% Opus 4.6):
- **Input tokens**: ~52% cheaper ($2.40 vs $5.00 per MTok)
- **Output tokens**: ~52% cheaper ($12.00 vs $25.00 per MTok)
- **Blended**: ~50% cost reduction
- **Speed**: 2â€“3Ã— faster on delegated tasks

> Note: Savings calculated against Opus 4.6 pricing ($5/$25 per MTok) as of February 2026.
> Savings would be significantly higher compared to Opus 4.1/4.0 ($15/$75 per MTok).

---

## ğŸ¯ Design Principles

### ğŸ«¥ Invisibility
> The user should **never** notice Hydra operating. No announcements, no permission requests, no process narration. If a head does the work, present the output as if Opus did it.

### âš¡ Speed Over Ceremony
> Don't overthink classification. Quick mental check: "Haiku? Sonnet? Me?" and go. If you spend 10 seconds classifying a 5-second task, you've defeated the purpose.

### ğŸ”€ Parallel Heads
> Independent subtasks launch in parallel. "Fix the bug AND add tests" â†’ two heads working simultaneously.

### â¬†ï¸ Escalate, Never Downgrade
> If a head's output isn't good enough, Opus does it directly. No retries at the same tier. This mirrors speculative decoding's rejection sampling â€” when a draft token is rejected, the target model samples directly.

---

## ğŸ”¬ The Speculative Decoding Connection

For those who want to go deeper, here's how Hydra maps to the original speculative decoding concepts:

| Speculative Decoding Concept | Hydra Equivalent |
|:-----------------------------|:-----------------|
| Target model (large) | ğŸ§  Opus 4.6 â€” the orchestrator |
| Draft model (small) | ğŸŸ¢ Haiku / ğŸ”µ Sonnet heads |
| Draft K tokens | Heads draft the full task output |
| Parallel verification | Opus glances at the output |
| Modified rejection sampling | Accept â†’ ship it. Reject â†’ Opus redoes it. |
| Acceptance rate (~70-90%) | Target: 85%+ of delegated tasks accepted as-is |
| Guaranteed â‰¥1 token per loop | Every task produces a result â€” Opus catches failures |
| Temperature/nucleus compatibility | Works with any coding task type or domain |

### Key Papers
- [Accelerating Large Language Model Decoding with Speculative Sampling](https://arxiv.org/abs/2302.01318) â€” Chen et al., 2023 (DeepMind)
- [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192) â€” Leviathan et al., 2022 (Google)

---

## ğŸ¤” FAQ

<details>
<summary><strong>Will I notice any quality difference?</strong></summary>
<br/>
No. Hydra only delegates tasks that are within each model's capability band. If there's any doubt, the task stays with Opus. And Opus always verifies â€” if a head's output isn't up to standard, Opus redoes it before you ever see it.
</details>

<details>
<summary><strong>Is this actually speculative decoding?</strong></summary>
<br/>
Not at the token level â€” that happens inside Anthropic's servers and we can't modify it. Hydra applies the same <em>philosophy</em> at the task level: draft with a fast model, verify with the powerful model, accept or reject. Same goals (speed + cost), same guarantees (zero quality loss), different granularity.
</details>

<details>
<summary><strong>What if I'm not using Opus?</strong></summary>
<br/>
Hydra is designed for the Opus-as-orchestrator pattern, but the principles apply at any tier. If you're running Sonnet as your main model, you could adjust the heads to use Haiku for everything delegatable.
</details>

<details>
<summary><strong>Can I customize which models the heads use?</strong></summary>
<br/>
Absolutely. Each head is a simple Markdown file with a <code>model:</code> field in the frontmatter. Change <code>model: haiku</code> to <code>model: sonnet</code> (or any supported model) and you're done.
</details>

<details>
<summary><strong>Do the heads work with subagents I already have?</strong></summary>
<br/>
Yes. Hydra heads coexist with any other subagents. Claude Code discovers all agents in the <code>.claude/agents/</code> directories. No conflicts.
</details>

<details>
<summary><strong>How do I uninstall?</strong></summary>
<br/>

```bash
./scripts/install.sh --uninstall
# ğŸ‰ All heads severed. Hydra sleeps.
```

</details>

---

## ğŸ¤ Contributing

Found a task type that gets misclassified? Have an idea for a new head? Contributions are welcome!

1. Fork it
2. Create your branch (`git checkout -b feature/hydra-new-head`)
3. Commit (`git commit -m 'Add hydra-optimizer head for perf tuning'`)
4. Push (`git push origin feature/hydra-new-head`)
5. Open a PR

---

## ğŸ“œ License

MIT â€” Use it, fork it, deploy it. Just don't use it for world domination.

*...unless it's code world domination. Then go ahead.*

---

<p align="center">
  <br/>
  <img src="https://img.shields.io/badge/ğŸ‰-HAIL_HYDRA-darkred?style=for-the-badge&labelColor=black" alt="Hail Hydra" />
  <br/><br/>
  <em>Built with ğŸ§  by Claude Opus 4.6 â€” ironically, the model this framework is designed to use less of.</em>
</p>

---
> Prefer a clean, technical version? See the [`spec-exec`](../../tree/spec-exec) branch â€” same framework, zero theatrics.
